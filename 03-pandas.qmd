---
title: "Introduction to Pandas and Seaborn"
author: "Bella Ratmelia"
format: revealjs
---

## Recap from yesterday

-  Python libraries / packages

-  Introduction to Numpy (+ numpy-financial)

-  Getting started with visualizations with matplotlib

## Overview for today

Today, we will cover the typical steps when doing data analysis projects. For this session, we will do simple time series analysis.

- Step 1: Loading and pre-processing data (with pandas)
- Step 2: Time Series analysis
- Step 3: Data Visualization (with Seaborn)

# Step 1: Loading and pre-processing data (with pandas)

## What's Pandas?

:::: {.columns}

::: {.column width="30%"}
![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Giant_Panda_Eating.jpg/1024px-Giant_Panda_Eating.jpg)
:::

::: {.column width="70%"}
> `pandas` is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,
built on top of the Python programming language. `pandas` aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. [^1] 

[^1]: <https://pandas.pydata.org/>

- Well-established Python library for data manipulation and analysis
- Built on top of NumPy. Unlike Numpy who can be difficult to "read", Dataframe presents data in tabular format that's easier for humans to read and perceive. 
- Provides DataFrame and Series data structures
- Many cheatsheets available: <https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf> or <https://python-graph-gallery.com/cheat-sheets/>
:::

:::: 

## Comparison to Numpy

| **Feature**               | **NumPy Array**                                                                                          | **pandas DataFrame**                                                                                             |
|---------------------------|----------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|
| **Data Types**             | All elements must be of the same type (e.g., integers, floats).                                           | Different columns can hold different data types (e.g., integers, floats, strings).                               |
| **Performance**            | Faster for numerical computations due to homogeneity and optimized implementation.                        | Slightly slower but more flexible for working with heterogeneous or labeled data.                                |
| **Dimensionality**         | Can be multi-dimensional (1D, 2D, 3D, etc.).                                                             | Always two-dimensional with labeled rows and columns.                                                            |
| **Indexing**               | Purely positional indexing (e.g., `array[0, 1]`).                                                        | Labeled-based indexing (`loc`), position-based indexing (`iloc`), access by both labels and positions.           |
| **Usage**                  | Primarily for high-performance numerical and scientific computations.                                     | Primarily for data manipulation, analysis, and cleaning, especially for tabular and real-world datasets.         |


## Installing and importing packages

To install this package, you can use this command:

`pip install pandas`

`pip install seaborn`

Remember, we must first import these packages to our notebook / script before we can use them.

```{python}
#| echo: true

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
```

::: {.callout-note appearance="simple" title="Pandas Cheatsheet"}
Have this cheatsheet open on another tab as you work through your data: <https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf> or <https://python-graph-gallery.com/cheat-sheets/>
:::

## Load data from CSV to DataFrame

::: {.callout-important appearance="simple" title="Before we begin..."}

[Right-click here to open `unemployment-age.csv`](https://raw.githubusercontent.com/bellaratmelia/2024-python-macroecons/main/data/unemployment-age.csv), and then Ctrl + S / Cmd + S to save it locally into your data folder

:::

Typically, we load the data from API source (more on this next week!) or external data file such as CSV. Let's load the `unemployment-age.csv` now!

```{python}
#| echo: true

unemp_data = pd.read_csv('data/unemployment-age.csv')
print(unemp_data.head())
```

## Initial checks: get basic info

The first thing that you should always do is check on the dataframe to get an overview of it. The function `info()` will tell us the data types for each columns, the number of observations, and index info if there's any.

```{python}
#| echo: true

unemp_data.info()
```

## Initial checks: get summary stats

Also get the summary statistics to get a sense of the shape and spread of your data. 

```{python}
#| echo: true

unemp_data.describe()
```

## Initial checks: column names

Optional, but you may also want to check on the column names to see how it appears in our environment (useful if you happen to have non UTF-8 characters as your column names)

```{python}
#| echo: true

print(unemp_data.columns)
```

## Dropping columns

In some cases, we don't really need the entire columns. Let's drop the last column (that looks like an error in the CSV formatting).

```{python}
#| echo: true

unemp_data.drop(unemp_data.columns[-1], axis = 1, inplace= True)
unemp_data.head()
```

## Renaming columns

Sometimes the column names are not ideal. In our case, let's give a name to each age group!

```{python}
#| echo: true

unemp_data.columns = ['date', 'teenagers', 'young_adults', 'adults', 'seniors']
print(unemp_data.columns)
```

Alternatively, if you just want to rename specific columns:

```python
unemp_data.rename(columns={'16_19yrs': 'teenagers', '20_24yrs': 'young_adults'}, inplace = True)
```

## Data preparation, analysis, and visualization tasks

Data preparation, analysis, and visualization tasks will be different depends on the dataset and your goal. Specifically for our data, we will do the following:

1. Check for and remove all the missing values.
2. We are primarily interested in the young adult unemployment. Separate this data into a new dataframe called `ya_unemp`.
3. Retrieve the months and years where the young adult rate is more than 10 percent and keep this on `high_ya_unemp`.
4. Add in a new column that tracks the total unemployment rate for each month.
5. Calculate the quarterly mean unemployment rate. 
6. Calculate the year-on-year change of unemployment rate.
7. Plot the unemployment rate over the years for each age group.
8. Are there any specific month where the unemployment rate tends to be higher? Plot the data.
9. Are there any outliers in the unemployment rate?

## Task 1 - Handling missing values

Other than `info()`, we can also use `isnull()` to check for null values

```{python}
#| echo: true

# Check for missing values
print(unemp_data.isnull().sum())
```

## Handling missing values: drop or no drop?

We can drop those rows that contains null values with `dropna()`... 

```{python}
#| echo: true
#| code-overflow: wrap

# Drop rows with missing values (if any)
unemp_data = unemp_data.dropna()
print(unemp_data.info())
```

... or we can also fill in the null values with something else, e.g. 0 

```python
uemp_data = unemp_data.fillna(0)
```

## Task 2 - Retrieving columns: a single column

As the column names in DataFrame are indexed, we can simply call them by their column names! (Much more intuitive compared to Numpy)

```{python}
#| echo: true
#| output-location: fragment

ya_unemp = unemp_data['young_adults']
ya_unemp.head()
```

## Retrieving columns: multiple columns

Similarly, if we want to retrieve multiple columns, we can pass **a list of column names** to the dataframe and save these sliced columns into a new dataframe.

```{python}
#| echo: true
#| output-location: fragment

ya_unemp = unemp_data[['date', 'young_adults']]
ya_unemp.head()
```

## Task 3 - Filtering row(s): without query()

We can do it "raw" or us the `query` function from pandas. Here is how you can do it without the `query()` function:

```{python}
#| echo: true
#| output-location: fragment

criteria = unemp_data["young_adults"] > 10
high_ya_unemp = unemp_data[criteria]
high_ya_unemp.head()
```

## Filtering row(s): with query()

And here is how you can do it with the `query()` function:

```{python}
#| echo: true
#| output-location: fragment

print(unemp_data.query('young_adults > 10'))
```

## Filtering row(s): with query() and save result

Take note that the previous code will simply print out the result! If you want to save the result, make sure to assign the result to a new dataframe.

```{python}
#| echo: true
#| output-location: fragment

high_ya_unemp = unemp_data.query('young_adults > 10')
high_ya_unemp.head()
```

## Task 4 - Adding new column(s)

Let's add a new column for total unemployment (sum of all age groups)

```{python}
#| echo: true
#| code-overflow: wrap

unemp_data['total_unemployment'] = unemp_data['teenagers'] + unemp_data['young_adults'] + unemp_data['adults'] + unemp_data['seniors']
unemp_data.head()
```

## Learning Check #1

Retrieve data where the employment rate for adults are between 9 to 12 inclusive. Save only the `date` and `adults` column to a new dataframe called `adult_unemp`

```{python}
#| echo: true
#| code-fold: true

adult_unemp = unemp_data[['date', 'adults']].query('adults >= 9 & adults <= 12')
print(adult_unemp.head())
print(adult_unemp.shape)

```

# Step 2: Time Series Analysis

## Side quest: DateTime Object 

- A `DateTime` object in Python, provided by the `datetime` module, represents a specific point in time, including the year, month, day, hour, minute, second, and microsecond. 
- It can be used to manipulate dates and times, perform arithmetic on dates, and format dates into other string representation e.g. from dd/mm/yyyy to yyyy-mm-dd.

```{python}
#| echo: true

from datetime import datetime

now = datetime.now()
print("Current Date and Time:", now)
```

## Components of DateTime

The `DateTime` object consists of multiple components that represent different parts of the date and time, such as year, month, day, hour, minute, second, etc. You can access these components individually.

```{python}
#| echo: true

# Extract year, month, and day from a specific date
now = datetime.now()

# Access individual components
print("Year:", now.year)
print("Month:", now.month)
print("Day:", now.day)
print("Hour:", now.hour)
print("Minute:", now.minute)
print("Second:", now.second)
```

## DateTime operations

- You can perform various operations with DateTime objects, such as calculating the difference between two dates or adding/subtracting time with the help of `timedelta`. 
- These are essential for time series data manipulation, where date-based arithmetic is often required.

```{python}
#| echo: true

from datetime import timedelta

now = datetime.now()

last_week = now - timedelta(days=7)
print("1 week ago:", last_week)
```

## Back to Main Quest: Time Series with DataFrame 

Let's index the rows under `date` column as a DateTime index. 

```{python}
#| echo: true
#| code-line-numbers: 1|2

unemp_data['date'] = pd.to_datetime(unemp_data['date'], format="%Y-%m-%d") # <1>
unemp_data.set_index('date', inplace=True) # <2>
```

1. Convert the data type under `date` column from string to `DateTime` object
2. Set the `date` column as the index. 

::: aside
You can refer to this page to see how to format the string expression of DateTime object: <https://www.w3schools.com/python/python_datetime.asp>
:::

## DateTime is the index, now what?

Let's check on the dataframe once more, to make sure that it is indexed as intended:

```{python}
#| echo: true

unemp_data.info()
```

If all goes well, the `date` column should be part of the index now.

## Extra checks with Time Series

Other things that we may want to check with Time Series is the date range of our data.

```{python}
#| echo: true

print("start date", unemp_data.index.min())
print("end date", unemp_data.index.max())
print("length", unemp_data.index.max() - unemp_data.index.min())
```

## Retrieve specific date range

Now that the index is a `DateTime` object, we can easily retrieve specific date range! Let's say we would like retrieve unemployment rate for during COVID, which will be March 2020 to May 2023.

```{python}
#| echo: true

unemp_data_covid = unemp_data.loc['2020-03':'2023-05']
print(unemp_data_covid.head())
```


## Task 5 - Resampling to Quarterly data and get the quarterly mean

With time series, we can calculate the quarterly average based on the monthly data with `resample()`

```{python}
#| echo: true

quarterly_data = unemp_data.resample('Q').mean()
print(quarterly_data.head())
```

## Resampling to Yearly data 

Let's find out what is the highest unemployment rate for each year!

```{python}
#| echo: true

yearly_data = unemp_data.resample('Y').max()
print(yearly_data.head())
```

## Saving into a CSV

Let's save the quarterly data to a CSV!

```{python}
#| echo: true

quarterly_data.to_csv("data-output/yearly-unemployment-age.csv")
```

## Changing the frequency of Time Series: More granular

Let's say we would like get a weekly time series. Since our data is a monthly one, there will be rows with empty values if we change the frequency. There are several methods that we can employ here to fill this empty values:

- backfill
- forward fill
- interpolate

```{python}
#| echo: true

unemp_data_weekly = unemp_data.resample('1W').ffill()
print(unemp_data_weekly.tail())
```

## Task 6 - Calculate year-on-year changes for young adults

Let's get the year-on-year change for young adults age group.

```{python}
#| echo: true

unemp_data['ya_YoY_pctchange'] = unemp_data['young_adults'].pct_change(periods=12) # multiply by 100 to get the %
print(unemp_data.tail())
```

## Calculate the changes for each month

To capture the direction and magnitude of changes in unemployment rate each month, use `diff()` function.

```{python}
#| echo: true

unemp_data['changes_ya'] = unemp_data['young_adults'].diff()
print(unemp_data['changes_ya'].head(7))
```

## Visualize the changes

Pandas is built on top of NumPy and integrates well with Matplotlib, so it is super easy to plot data right awayâ€”especially now that we've set the index!

```{python}
#| echo: true

unemp_data['changes_ya'].plot()
```

## Learning Check #2

Change the frequency of the time series to weekly, and interpolate the numbers. Save this new series into `unemp_weekly_interpolate`

```{python}
#| echo: true
#| code-fold: true

unemp_weekly_interpolate = unemp_data.resample('1W').interpolate()
print(unemp_weekly_interpolate.tail())

```

# Step 3: Data visualization

## What's Seaborn?

:::: {.columns}

::: {.column width="40%"}
![](https://seaborn.pydata.org/_static/logo-wide-lightbg.svg)
:::

::: {.column width="60%"}
> Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. [^2]  

[^2]: <https://seaborn.pydata.org/>

- Well-established Python library for data visualization
- Cheatsheet by Datacamp here: <https://python-graph-gallery.com/cheat-sheets/>
:::

:::: 

Some setups we can do:

```{python}
#| echo: true

import seaborn as sns
sns.set_style("whitegrid")
sns.set_palette("husl")
```

## Task 7 - Plot the entire time series

Let's plot the unemployment rate over the years for each age group! 

```{python}
#| echo: true
#| output-location: slide

unemp_data.plot()
plt.title('Unemployment Rate for Young Adults')
plt.ylabel('Unemployment Rate (%)')
plt.show()
```

## Plotting *some* parts of the time series

Clearly, there are some columns that we may want to skip. To do this, we can reshape the data shape into long format using `melt()`. 

Let's say we only want to visualize `teenagers` and `young_adults`.

```{python}
#| echo: true
#| output: false
#| code-overflow: wrap
#| code-line-numbers: 1|2|3

youth_data = unemp_data[['teenagers', 'young_adults']] # <1>
youth_data = youth_data.reset_index() # <2>
youth_data_melted = youth_data.melt(id_vars='date', value_vars=['teenagers', 'young_adults'], var_name='age_group', value_name='unemployment_rate') # <3>

```

1. Retrieve the columns that we need (index will be automatically included)
2. Reset the index, so that it's back to normal column.
3. Use the melt() function to "melt" the wide data into long format

## Wide data vs Long data

Check out the difference!

::: {.columns}
::: {.column}
Wide Data

```{python}
print(unemp_data[['teenagers', 'young_adults']])
```
:::
::: {.column}
Long Data

```{python}
print(youth_data_melted)
```
:::
::: 

## Visualizing is much easier with long data

We can now fit the things we want in a single line like so:

```{python}
#| echo: true

sns.lineplot(data=youth_data_melted, x='date', y='unemployment_rate', hue='age_group')
```

## Making visualization easier: Capture month info into a separate column

With `DateTime` object as the index, we can easily capture the month info. This would be useful to see whether certain months tend to have higher unemployment rate based on this data. 

```{python}
#| echo: true

unemp_data['month'] = unemp_data.index.month
print(unemp_data.head())
```

## Aggregate statistics

Let's calculate the average unemployment rate for each month based on this data.

```{python}
#| echo: true

unemp_permonth = unemp_data.groupby('month').mean()
print(unemp_permonth)
```


## Task 8 - Months where unemployment rate then to be high

Which month seems to have the highest unemployment rate on average?

``` {python}
#| echo: true

sns.barplot(data = unemp_permonth, x = unemp_permonth.index, y = 'young_adults')
```

## Task 9 - Finding outliers

Let's see how unemployment rate fared each month for `young_adults`. Are there any outliers?

``` {python}
#| echo: true

sns.boxplot(x = 'month', y = 'young_adults', data=unemp_data[['month', 'young_adults']])
```

## More Seaborn: Scatterplot

Seaborn can do many other visualizations as well. For example, let's try plotting a scatterplot of `young_adults` and `seniors`

``` {python}
#| echo: true

sns.scatterplot(x = 'young_adults', y = 'seniors', data = unemp_data)
```

## More Seaborn: Regplot

Let's try plotting a regression plot of `young_adults` and `seniors`

``` {python}
#| echo: true

sns.regplot(x = 'young_adults', y = 'seniors', data = unemp_data)
```


## Learning Check #3

Plot the unemployment rate fared each month for `young_adults` with violin plot to see the distribution better. 

```{python}
#| echo: true
#| code-fold: true

sns.violinplot(x = 'month', y = 'young_adults', data=unemp_data[['month', 'young_adults']])

```

# End of Session 3!
 
We have covered pandas and Seaborn! 